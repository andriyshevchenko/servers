# Performance Improvements

This document describes the performance optimizations implemented in the Memory-Enhanced MCP Server.

## Overview

Multiple performance bottlenecks were identified and addressed, resulting in significant performance improvements:
- **42x speedup** for cached read operations
- **O(1) entity lookups** instead of O(n) linear search
- **Optimized conflict detection** with pre-computation
- **Efficient graph traversal** with adjacency lists

## Key Optimizations

### 1. Graph Caching Layer

**Problem**: Every operation loaded the entire graph from storage, resulting in O(total_entities + total_relations) overhead per operation.

**Solution**: Implemented intelligent caching with invalidation:
- `loadGraphCached(forceRefresh)` - loads graph with optional caching
- Read-only operations use cache (searchNodes, queryNodes, getMemoryStats, etc.)
- Write operations force refresh and invalidate cache
- Cache is automatically invalidated after mutations

**Impact**: **42.41x speedup** for repeated read operations
- Before: 2.34ms per read
- After: 0.06ms per cached read

**Files Modified**: `knowledge-graph-manager.ts`

```typescript
// Before: Every operation loaded full graph
const graph = await this.storage.loadGraph();

// After: Read operations use cache
const graph = await this.loadGraphCached(); // Uses cache

// Write operations force refresh
const graph = await this.loadGraphCached(true); // Forces reload
// ... mutations ...
await this.saveGraphAndInvalidate(graph); // Saves and invalidates
```

### 2. Entity Name Indexing

**Problem**: Entity lookups used linear search `entities.find(e => e.name === entityName)`, resulting in O(n) complexity.

**Solution**: Built Map-based index for O(1) lookups:
- Index is built when graph is loaded: `Map<entityName, Entity>`
- `findEntityFast()` uses index with fallback to linear search
- Index is automatically rebuilt when cache is refreshed

**Impact**: **0.30ms average** for entity lookups with 500 entities

**Files Modified**: `knowledge-graph-manager.ts`

```typescript
// Build index on load
private buildEntityIndex(graph: KnowledgeGraph): void {
  this.entityIndex = new Map();
  for (const entity of graph.entities) {
    this.entityIndex.set(entity.name, entity);
  }
}

// O(1) lookup using index
private findEntityFast(graph: KnowledgeGraph, entityName: string): Entity {
  if (this.entityIndex) {
    const entity = this.entityIndex.get(entityName);
    if (entity) return entity;
  }
  // Fallback to linear search if needed
  return graph.entities.find(e => e.name === entityName);
}
```

### 3. Optimized Conflict Detection

**Problem**: O(n²) nested loops with repeated string operations inside:
- `toLowerCase()` called multiple times per observation pair
- `Array.from(NEGATION_WORDS)` called repeatedly
- `split(/\s+/)` called in nested loops

**Solution**: Pre-compute expensive operations:
- Cache NEGATION_WORDS as static array
- Pre-compute lowercase content and negation flags for all observations before nested loops
- Reuse computed values instead of recalculating

**Impact**: **1.52ms** to detect conflicts in 50 entities with 200 observations

**Files Modified**: `knowledge-graph-manager.ts`

```typescript
// Before: Repeated operations in nested loops
for (let i = 0; i < entity.observations.length; i++) {
  for (let j = i + 1; j < entity.observations.length; j++) {
    const obs1Content = entity.observations[i].content.toLowerCase(); // Repeated
    const obs2Content = entity.observations[j].content.toLowerCase(); // Repeated
    const obs1HasNegation = Array.from(NEGATION_WORDS).some(...); // Repeated conversion
    // ...
  }
}

// After: Pre-compute before loops
const obsData = entity.observations.map(obs => {
  const content = obs.content.toLowerCase(); // Once per observation
  const hasNegation = negationWordsArray.some(...); // Use cached array
  return { obs, content, hasNegation };
});

for (let i = 0; i < obsData.length; i++) {
  for (let j = i + 1; j < obsData.length; j++) {
    // Use pre-computed values
    const obs1Data = obsData[i];
    const obs2Data = obsData[j];
    // ...
  }
}
```

### 4. Efficient Graph Traversal

**Problem**: `getContext()` filtered entire relations array for each entity at each depth level, resulting in O(depth × entities × relations) complexity.

**Solution**: Built adjacency list for O(1) neighbor lookups:
- Construct adjacency map once: `Map<entityName, Set<neighborNames>>`
- Direct neighbor access without filtering

**Impact**: **0.41-0.55ms** for depth 2-3 queries on 200 entities

**Files Modified**: `knowledge-graph-manager.ts`

```typescript
// Before: Filter entire relations array per entity per depth
for (let d = 0; d < depth; d++) {
  for (const entityName of currentEntities) {
    const relatedRelations = graph.relations.filter(r => 
      r.from === entityName || r.to === entityName
    ); // O(relations) per entity per depth
  }
}

// After: Build adjacency list and lookup neighbors
const adjacencyMap = new Map<string, Set<string>>();
for (const relation of graph.relations) {
  // Build map once
  adjacencyMap.get(relation.from)!.add(relation.to);
  adjacencyMap.get(relation.to)!.add(relation.from);
}

for (let d = 0; d < depth; d++) {
  for (const entityName of currentEntities) {
    const neighbors = adjacencyMap.get(entityName); // O(1) lookup
    if (neighbors) {
      neighbors.forEach(n => contextEntityNames.add(n));
    }
  }
}
```

## Performance Benchmarks

All benchmarks are included in `__tests__/performance-benchmark.test.ts`.

### Test Results

| Operation | Dataset | Before (est) | After | Speedup |
|-----------|---------|-------------|-------|---------|
| Repeated reads | 100 entities | 2.34ms/read | 0.06ms/read | **42.41x** |
| Entity lookups | 500 entities | ~5-10ms | 0.30ms | **~17-33x** |
| Conflict detection | 50 entities, 200 obs | ~10-20ms | 1.52ms | **~7-13x** |
| Context depth 2 | 200 entities | ~5-10ms | 0.41ms | **~12-24x** |
| Query nodes | 300 entities | Similar | 5.90ms | Stable |

### How to Run Benchmarks

```bash
cd src/memory-enhanced
npm test performance-benchmark
```

## Architecture Changes

### Cache Invalidation Strategy

```
READ OPERATIONS (use cache):
- searchNodes
- openNodes  
- queryNodes
- getAllEntityNames
- listEntities
- getMemoryStats
- getRecentChanges
- findRelationPath
- detectConflicts
- getContext
- getObservationHistory
- getFlaggedEntities
- getAnalytics
- listConversations

WRITE OPERATIONS (force refresh + invalidate):
- createEntities
- createRelations
- addObservations
- updateObservation
- deleteEntities
- deleteObservations
- deleteRelations
- pruneMemory
- bulkUpdate
- flagForReview
```

### Memory Usage

The caching layer adds minimal memory overhead:
- **Graph cache**: 1x graph in memory (same as before, but reused)
- **Entity index**: ~40 bytes per entity (Map overhead + string reference)
- **Adjacency list**: Built on-demand in getContext, not cached

For a typical graph with 1000 entities and 3000 relations:
- Graph cache: Same as before (already in memory during operations)
- Entity index: ~40 KB additional
- Total overhead: **< 50 KB**

## Backward Compatibility

All optimizations are transparent to users:
- ✅ All existing tests pass (221/221)
- ✅ No API changes
- ✅ Same storage format
- ✅ Same behavior, just faster

## Future Optimizations

Potential areas for further improvement:
1. **Relation indexing**: Build Map for relation lookups by (from, to, relationType)
2. **Observation indexing**: Index observations by content hash for faster duplicate detection
3. **Streaming JSONL parsing**: For very large files, use streaming instead of loading entire file
4. **LRU cache**: If memory becomes a concern, implement LRU cache with size limit
5. **Incremental updates**: Instead of invalidating entire cache, update only changed portions

## Migration Guide

No migration needed! The optimizations are drop-in replacements that work with existing data and code.

## Testing

All performance improvements are covered by tests:
- **Unit tests**: Existing 215 tests still pass
- **Performance benchmarks**: New 6 tests validate improvements
- **Total**: 221 tests passing

Run tests:
```bash
npm test                      # All tests
npm test performance-benchmark # Just benchmarks
```

## Conclusion

These optimizations provide significant performance improvements with minimal code changes and no breaking changes. The caching layer alone provides **42x speedup** for read-heavy workloads, which is typical for MCP servers.
